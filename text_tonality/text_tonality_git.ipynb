{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c42aa6",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Описание-задачи\" data-toc-modified-id=\"Описание-задачи-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Описание задачи</a></span><ul class=\"toc-item\"><li><span><a href=\"#Постановка-задачи\" data-toc-modified-id=\"Постановка-задачи-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Постановка задачи</a></span></li><li><span><a href=\"#Ход-исполнения\" data-toc-modified-id=\"Ход-исполнения-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Ход исполнения</a></span></li></ul></li><li><span><a href=\"#Обзор-данных\" data-toc-modified-id=\"Обзор-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обзор данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-инструментов\" data-toc-modified-id=\"Загрузка-инструментов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Загрузка инструментов</a></span></li><li><span><a href=\"#Описание-данных\" data-toc-modified-id=\"Описание-данных-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Описание данных</a></span></li><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Загрузка данных</a></span></li></ul></li><li><span><a href=\"#Подготовка-наборов\" data-toc-modified-id=\"Подготовка-наборов-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Подготовка наборов</a></span></li><li><span><a href=\"#Модели\" data-toc-modified-id=\"Модели-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Подготовка-наборов\" data-toc-modified-id=\"Подготовка-наборов-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Подготовка наборов</a></span></li><li><span><a href=\"#Модели-на-полном-наборе\" data-toc-modified-id=\"Модели-на-полном-наборе-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Модели на полном наборе</a></span></li><li><span><a href=\"#Модели-на-downsampling-наборе\" data-toc-modified-id=\"Модели-на-downsampling-наборе-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Модели на downsampling-наборе</a></span></li><li><span><a href=\"#Модели-на-BERT-эмбеддингах-(DistilBertModel)\" data-toc-modified-id=\"Модели-на-BERT-эмбеддингах-(DistilBertModel)-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Модели на BERT-эмбеддингах (DistilBertModel)</a></span></li><li><span><a href=\"#Sanity-Check\" data-toc-modified-id=\"Sanity-Check-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Sanity Check</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe63b31",
   "metadata": {},
   "source": [
    "# КЛАССИФИКАЦИЯ ТОКСИЧНОСТИ ТЕКСТА"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ef8c3",
   "metadata": {},
   "source": [
    "## Описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03fe75",
   "metadata": {},
   "source": [
    "### Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cd83c",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. Заказчик представил набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Необходимо построить модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e9715",
   "metadata": {},
   "source": [
    "### Ход исполнения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bef3c",
   "metadata": {},
   "source": [
    "1. Загрузим и исследуем данные.\n",
    "2. Проанализируем данные.\n",
    "3. Обучим разные модели, включая BERT.\n",
    "4. Проверим модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50314f61",
   "metadata": {},
   "source": [
    "## Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd2cce",
   "metadata": {},
   "source": [
    "### Загрузка инструментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f5cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (4.16.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (0.11.5)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (2020.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44417745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\1\\anaconda3\\envs\\praktikum\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# общие библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd52a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "# нейросети\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "# скоринг\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# утилиты\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8b05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# классическое преобразование текста\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2a7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fbd480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# настройки\n",
    "import warnings\n",
    "\n",
    "from tqdm import notebook\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b425869",
   "metadata": {},
   "source": [
    "### Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc7db5",
   "metadata": {},
   "source": [
    "Описание данных предоставлено заказчиком."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ad3e3",
   "metadata": {},
   "source": [
    "Столбец `text` в содержит текст комментария, а `toxic` — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c1684",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f4ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем файл и сохраняем в переменные дальнейшей работы, в том числе изменений\n",
    "# используем оператор обработки исключений, чтобы избежать ошибки, при открытии данных,\n",
    "# расположенных по другому адресу \n",
    "try: \n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('datasets/toxic_comments.csv')\n",
    "                         \n",
    "# создадим дополнительные переменные, для контроля изменений    \n",
    "try: \n",
    "    df_ctrl = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df_ctrl = pd.read_csv('datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c658348a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119105</th>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131631</th>\n",
       "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125326</th>\n",
       "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111256</th>\n",
       "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83590</th>\n",
       "      <td>(and if such phrase exists, it would be provid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "119105  Geez, are you forgetful!  We've already discus...      0\n",
       "131631  Carioca RFA \\n\\nThanks for your support on my ...      0\n",
       "125326  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...      0\n",
       "111256  Pseudoscience category? \\n\\nI'm assuming that ...      0\n",
       "83590   (and if such phrase exists, it would be provid...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим работу данных\n",
    "df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea41f8a",
   "metadata": {},
   "source": [
    "Изучим данные более внимательно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e182ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cedee4",
   "metadata": {},
   "source": [
    "Проверим данные на дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0b835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['text'].duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924670e",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "1. Данные загружены и функционируют.\n",
    "2. Пропуски отсутствуют.\n",
    "3. Тип данных соответствует содержанию колонок."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390402e",
   "metadata": {},
   "source": [
    "## Подготовка наборов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5595bc",
   "metadata": {},
   "source": [
    "Создадим корпус текстов, приведем их все к нижнему регистру и необходимой кодировке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca7713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cbfd08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31645d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corpus\n",
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04d34f",
   "metadata": {},
   "source": [
    "Изучим распределение классов в целевом признаке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a34790a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic\n",
       "0  0.898321\n",
       "1  0.101679"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6f484",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "Набор содержит только 10% положительных классов. Это необходимо учесть при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b76a65",
   "metadata": {},
   "source": [
    "## Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232af319",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f6090",
   "metadata": {},
   "source": [
    "Получим леммы, избавимся от лишних символов, а также преобразуем текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14da74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    joined = ' '.join(tokenized)\n",
    "    text_only = re.sub(r\"[^a-z0-9!@#\\$%\\^\\&\\*_\\-,\\.' ]\", ' ', joined)\n",
    "    final = ' '.join(text_only.split())\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd7dbbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [01:57<00:00, 1355.09it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas() \n",
    "df['token_text'] = df['text'].progress_apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174b35e",
   "metadata": {},
   "source": [
    "Выделим и преобразуем в отдельный массив лемматизированный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1614720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemms = df['token_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e42dc9",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "1. Мы получили леммы слов, а также подготовили данные для дальнейшего машинного обучения. \n",
    "2. Наблюдается сильный дисбаланс классов, поэтому попробуем два способа борьбы с ним:\n",
    "- downsampling\n",
    "- class_weight = balance\n",
    "3. Проверим работу трех моделей: логистической регрессии, случайного леса и SGD классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3703d",
   "metadata": {},
   "source": [
    "### Подготовка наборов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c20c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 'token_text'\n",
    "target = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990a11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bd9f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce27691",
   "metadata": {},
   "source": [
    "Подготовим downsampling выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b626be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_sample = features_zeros.sample(frac=0.1, random_state=42)\n",
    "    target_sample = target_zeros.sample(frac=0.1, random_state=42)\n",
    "    \n",
    "    features_downsampled = pd.concat([features_sample] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_sample] + [target_ones])\n",
    "    \n",
    "    features_downsampled = shuffle(features_downsampled, random_state=42)\n",
    "    target_downsampled = shuffle(target_downsampled, random_state=42)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7af5c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dwnsmpld, y_train_dwnsmpld = downsample(X_train, y_train, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66f808",
   "metadata": {},
   "source": [
    "Проверим размеры получившихся наборов и распределение классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a1c2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27503, 27503)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_dwnsmpld), len(y_train_dwnsmpld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ba4c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.530924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.469076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic\n",
       "1  0.530924\n",
       "0  0.469076"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dwnsmpld.value_counts(normalize=True).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5f153",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "1. Подготовили поные обучающий и тестовый наборы.\n",
    "2. Подготовили наборы с уменьшенным количеством классов, чтобы избежать дисбаланса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fca05",
   "metadata": {},
   "source": [
    "### Модели на полном наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96458973",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_score = {}\n",
    "models_score['model_name'] = []\n",
    "models_score['f1_score'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8be3db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_mod = LogisticRegression(solver=\"liblinear\", random_state=42, class_weight='balanced')\n",
    "rfc_mod = RandomForestClassifier(n_estimators=10, random_state=42, class_weight='balanced')\n",
    "sgb_mod = SGDClassifier(max_iter = 1000, random_state=42, loss='modified_huber', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b821065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_slave(estimators, X_train, X_test, y_train, y_test, name):\n",
    "    models_score['model_name'].append(name)\n",
    "    \n",
    "    count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "    tf_idf_train = count_tf_idf.fit_transform(X_train)\n",
    "    tf_idf_test = count_tf_idf.transform(X_test)\n",
    "    \n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=estimators,\n",
    "        voting='soft', verbose=True)\n",
    "    \n",
    "    voting_clf.fit(tf_idf_train, y_train)\n",
    "    predict = voting_clf.predict(tf_idf_test)\n",
    "    f_score = round(f1_score(predict, y_test), 4)\n",
    "    models_score['f1_score'].append(f_score)\n",
    "    print(f'Итоговый f1 score: {f_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bbd4d57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (1 of 3) Processing logr, total=   2.1s\n",
      "[Voting] ...................... (2 of 3) Processing rfc, total= 1.9min\n",
      "[Voting] ...................... (3 of 3) Processing sgb, total=   0.6s\n",
      "Итоговый f1 score: 0.7899\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_slave([('logr', logr_mod), ('rfc', rfc_mod), ('sgb', sgb_mod)], \n",
    "         X_train, X_test, y_train, y_test, \n",
    "         'VotingClassifier (LR, RFC, SGB) на основе полного набора')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7238cbb",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "Обобщение через VotingClassifier показало проходной результат меры f1=0.79. Что является допустимым."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be46f3f",
   "metadata": {},
   "source": [
    "### Модели на downsampling-наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5be37ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_mod = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rfc_mod = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "sgb_mod = SGDClassifier(max_iter = 1000, random_state=42, loss='modified_huber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bd6fbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (1 of 3) Processing logr, total=   0.2s\n",
      "[Voting] ...................... (2 of 3) Processing rfc, total=   7.4s\n",
      "[Voting] ...................... (3 of 3) Processing sgb, total=   0.1s\n",
      "Итоговый f1 score: 0.648\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_slave([('logr', logr_mod), ('rfc', rfc_mod), ('sgb', sgb_mod)],\n",
    "         X_train_dwnsmpld, X_test, y_train_dwnsmpld, y_test, \n",
    "         'VotingClassifier на основе downsampling-набора')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26b572",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "Обобщение через VotingClassifier по downsampling-набору показало результат меры f1=0.66. Что значительно хуже полной выборки и не проходит по требованиям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594fbb7d",
   "metadata": {},
   "source": [
    "### Модели на BERT-эмбеддингах (DistilBertModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7131f",
   "metadata": {},
   "source": [
    "Проверим результаты при работе на модели DistilBert. При этом, используем только часть данных, чтобы сократить время обучения. Что, несомненно, скажется на результате.\n",
    "\n",
    "Подготовим набор со сбалансированным количеством классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdbfebd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic\n",
       "1  0.523333\n",
       "0  0.476667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_b = X_train_dwnsmpld.sample(300, random_state=42)\n",
    "y_train_b =  df.iloc[X_train_b.index]['toxic']\n",
    "\n",
    "# проверим результат\n",
    "y_train_b.value_counts(normalize=True).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39eb2f7",
   "metadata": {},
   "source": [
    "Классы распределны практически равномерно, выборки подготовлены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e604b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовим параметры\n",
    "configuration = transformers.DistilBertConfig()\n",
    "model = transformers.DistilBertModel(configuration)\n",
    "pretrained_weights = 'distilbert-base-uncased'\n",
    "tokenizer_class = transformers.DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda2ec6",
   "metadata": {},
   "source": [
    "При этом как BERT так и DistilBert обучены работе только с предложениями длинной до 512 символов. Однако, в связи с необходимостью экономить GPU, сократим длину строки до 256. Несомненно, это также скажется на качестве обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd6b8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "tokenized = X_train_b.apply(\n",
    "    lambda x: tokenizer.encode(x[:256], add_special_tokens=True))\n",
    "\n",
    "padded = np.array([i + [0]*(256 - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55a65d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 256), (300, 256))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим результат\n",
    "padded.shape, attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "411b6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f63c695162a4729b3066d007f000909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33681c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a59db",
   "metadata": {},
   "source": [
    "Подготовим тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "483bb2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = X_test.sample(200, random_state=42)\n",
    "y_test_b =  df.iloc[X_test_b.index]['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbd14df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "tokenized = X_test_b.apply(\n",
    "    lambda x: tokenizer.encode(x[:256], add_special_tokens=True))\n",
    "\n",
    "padded = np.array([i + [0]*(256 - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b2f500d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 256), (200, 256))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим результат\n",
    "padded.shape, attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19ef2c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3feb0bd1884c9cadbb44c97e3c33f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98e02373",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f14a5b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (1 of 3) Processing logr, total=   0.2s\n",
      "[Voting] ...................... (2 of 3) Processing rfc, total=   0.1s\n",
      "[Voting] ...................... (3 of 3) Processing sgb, total=   0.0s\n",
      "Итоговый f1 score: 0.2526\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "        estimators=[('logr', logr_mod), ('rfc', rfc_mod), ('sgb', sgb_mod)],\n",
    "        voting='soft', verbose=True)\n",
    "    \n",
    "voting_clf.fit(X_train_b, y_train_b)\n",
    "predict = voting_clf.predict(X_test_b)\n",
    "f_score = round(f1_score(predict, y_test_b), 4)\n",
    "models_score['model_name'].append('VotingClassifier на основе BERT-эмбеддингов')\n",
    "models_score['f1_score'].append(f_score)\n",
    "print(f'Итоговый f1 score: {f_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fe08934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистим кэш\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c7bcb",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "Модель ожидаемо продемонстрировала показала метрику f1 ниже целевой (при учете сокращенной длины комментариев в два раза, а также сокращенной выборки в 300 наблюдений).\n",
    "\n",
    "При этом, подобная предобработка требует значительных GPU мощностей и затрат времени."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425ae5d",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8906c",
   "metadata": {},
   "source": [
    "Проверим адекватность моделей на основе классификатора, предсказывающего везде токсичный исход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe8fa1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(random_state=42, strategy='constant', constant=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "089c6421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ....................... (1 of 1) Processing dm, total=   0.0s\n",
      "Итоговый f1 score: 0.1846\n"
     ]
    }
   ],
   "source": [
    "ml_slave([('dm', dummy)], \n",
    "         X_train, X_test, y_train, y_test, \n",
    "         'Константная модель на основе DummyClassifier (constant=1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88edaec6",
   "metadata": {},
   "source": [
    "**Итоги:**\n",
    "\n",
    "Константная модель показала наихудшую метрику f1, что подтверждает эффективность применения алгоритмов МО."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bce6df",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdedcff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_91278_row0_col1 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_91278_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >model_name</th>\n",
       "      <th class=\"col_heading level0 col1\" >f1_score</th>\n",
       "      <th class=\"col_heading level0 col2\" >approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_91278_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_91278_row0_col0\" class=\"data row0 col0\" >VotingClassifier (LR, RFC, SGB) на основе полного набора</td>\n",
       "      <td id=\"T_91278_row0_col1\" class=\"data row0 col1\" >0.789900</td>\n",
       "      <td id=\"T_91278_row0_col2\" class=\"data row0 col2\" >yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91278_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_91278_row1_col0\" class=\"data row1 col0\" >VotingClassifier на основе downsampling-набора</td>\n",
       "      <td id=\"T_91278_row1_col1\" class=\"data row1 col1\" >0.648000</td>\n",
       "      <td id=\"T_91278_row1_col2\" class=\"data row1 col2\" >not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91278_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_91278_row2_col0\" class=\"data row2 col0\" >VotingClassifier на основе BERT-эмбеддингов</td>\n",
       "      <td id=\"T_91278_row2_col1\" class=\"data row2 col1\" >0.252600</td>\n",
       "      <td id=\"T_91278_row2_col2\" class=\"data row2 col2\" >not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91278_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_91278_row3_col0\" class=\"data row3 col0\" >Константная модель на основе DummyClassifier (constant=1)</td>\n",
       "      <td id=\"T_91278_row3_col1\" class=\"data row3 col1\" >0.184600</td>\n",
       "      <td id=\"T_91278_row3_col2\" class=\"data row3 col2\" >not</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ece585a88>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table = pd.DataFrame(models_score).sort_values(by='f1_score', ascending=False)\n",
    "score_table['approved'] = score_table['f1_score'].apply(lambda x: 'yes' if x >= 0.75 else 'not')\n",
    "score_table.style.highlight_max('f1_score', color = 'green', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b3eec",
   "metadata": {},
   "source": [
    "Для анализа тональности текста, нами был выбран ансамбль моделей (LogisticRegression, RandomForestClassifier, SGBClassifier). \n",
    "\n",
    "Наилучший результат целевой метрики был достигнут при использовании полной выборки, с балансированным весом классов. При этом, данная модель показала хорошие характеристики по времени обучения.\n",
    "\n",
    "Кроме того, ансамбль был обучен на следующих наборах:\n",
    "- downsampling-набор;\n",
    "- BERT-эмбеддинги;\n",
    "- константная модель.\n",
    "\n",
    "Модели, обученные на этих наборах не прошли по значению целевой метрики. Кроме того, константная модель продемонстрировала самую низкую оценку, что подтверждает sanity check остальных моделей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
